{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b405d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#train data\n",
    "X_train = df_train.iloc[:, 1:].values\n",
    "Y_train = df_train.iloc[:, 0].values\n",
    "\n",
    "#test data\n",
    "X_test = df_test.iloc[:, :784].values\n",
    "Y_test = df_test.iloc[:, 784].values\n",
    "\n",
    "#changing to tensor\n",
    "X_train_ten = torch.from_numpy(X_train).float()\n",
    "Y_train_ten = torch.from_numpy(Y_train).long()\n",
    "\n",
    "X_test_ten = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41bb461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 784])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9e0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 fold splitting\n",
    "N = X_train.shape[0]\n",
    "fold_size = N//4\n",
    "\n",
    "splits_data = []\n",
    "\n",
    "for fold in range(4):\n",
    "    start = fold*fold_size\n",
    "    end = (start + fold_size) if fold < 3 else N\n",
    "\n",
    "    X_val = X_train_ten[start:end]\n",
    "    Y_val = Y_train_ten[start:end]\n",
    "\n",
    "    X_tr = np.vstack((X_train_ten[:start],X_train_ten[end:]))\n",
    "    Y_tr = np.concatenate((Y_train_ten[:start],Y_train_ten[end:]))\n",
    "\n",
    "    splits_data.append((X_tr, Y_tr, X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afa95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = len(np.unique(Y_train))\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "# print(num_classes)\n",
    "\n",
    "# #data training and loading\n",
    "# for X_tr, Y_tr, X_val, Y_val in splits_data:\n",
    "\n",
    "#     train_dataset = TensorDataset(X_tr,Y_tr)\n",
    "#     test_dataset = TensorDataset(X_val,Y_val)\n",
    "\n",
    "#     train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n",
    "#     test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ten,Y_train_ten)\n",
    "test_dataset = TensorDataset(X_test_ten)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=64,shuffle=False)\n",
    "\n",
    "examples = next(iter(test_loader))\n",
    "example_data = examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, ouput_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size,ouput_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size,hidden_size,num_classes).to(device)\n",
    "\n",
    "#Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20451bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/420], Loss [0.40081965923309326]\n",
      "Epoch [1/100], Step [200/420], Loss [0.4748636484146118]\n",
      "Epoch [1/100], Step [300/420], Loss [0.39880111813545227]\n",
      "Epoch [1/100], Step [400/420], Loss [0.42630454897880554]\n",
      "Epoch [2/100], Step [100/420], Loss [0.3179425895214081]\n",
      "Epoch [2/100], Step [200/420], Loss [0.45024922490119934]\n",
      "Epoch [2/100], Step [300/420], Loss [0.34330645203590393]\n",
      "Epoch [2/100], Step [400/420], Loss [0.40921828150749207]\n",
      "Epoch [3/100], Step [100/420], Loss [0.25752362608909607]\n",
      "Epoch [3/100], Step [200/420], Loss [0.4787239730358124]\n",
      "Epoch [3/100], Step [300/420], Loss [0.31863924860954285]\n",
      "Epoch [3/100], Step [400/420], Loss [0.3813324272632599]\n",
      "Epoch [4/100], Step [100/420], Loss [0.2601436674594879]\n",
      "Epoch [4/100], Step [200/420], Loss [0.44279876351356506]\n",
      "Epoch [4/100], Step [300/420], Loss [0.3147488534450531]\n",
      "Epoch [4/100], Step [400/420], Loss [0.19391697645187378]\n",
      "Epoch [5/100], Step [100/420], Loss [0.2984326481819153]\n",
      "Epoch [5/100], Step [200/420], Loss [0.3024553954601288]\n",
      "Epoch [5/100], Step [300/420], Loss [0.35715243220329285]\n",
      "Epoch [5/100], Step [400/420], Loss [0.36217957735061646]\n",
      "Epoch [6/100], Step [100/420], Loss [0.15905380249023438]\n",
      "Epoch [6/100], Step [200/420], Loss [0.2909732162952423]\n",
      "Epoch [6/100], Step [300/420], Loss [0.4844823181629181]\n",
      "Epoch [6/100], Step [400/420], Loss [0.37256360054016113]\n",
      "Epoch [7/100], Step [100/420], Loss [0.2651923596858978]\n",
      "Epoch [7/100], Step [200/420], Loss [0.3137844502925873]\n",
      "Epoch [7/100], Step [300/420], Loss [0.29735589027404785]\n",
      "Epoch [7/100], Step [400/420], Loss [0.4795057773590088]\n",
      "Epoch [8/100], Step [100/420], Loss [0.3748813271522522]\n",
      "Epoch [8/100], Step [200/420], Loss [0.45098504424095154]\n",
      "Epoch [8/100], Step [300/420], Loss [0.3223348557949066]\n",
      "Epoch [8/100], Step [400/420], Loss [0.2196362316608429]\n",
      "Epoch [9/100], Step [100/420], Loss [0.2567524313926697]\n",
      "Epoch [9/100], Step [200/420], Loss [0.26889073848724365]\n",
      "Epoch [9/100], Step [300/420], Loss [0.2183402180671692]\n",
      "Epoch [9/100], Step [400/420], Loss [0.36514270305633545]\n",
      "Epoch [10/100], Step [100/420], Loss [0.20605367422103882]\n",
      "Epoch [10/100], Step [200/420], Loss [0.1337105929851532]\n",
      "Epoch [10/100], Step [300/420], Loss [0.32660284638404846]\n",
      "Epoch [10/100], Step [400/420], Loss [0.23392559587955475]\n",
      "Epoch [11/100], Step [100/420], Loss [0.4066663682460785]\n",
      "Epoch [11/100], Step [200/420], Loss [0.3651804029941559]\n",
      "Epoch [11/100], Step [300/420], Loss [0.284113347530365]\n",
      "Epoch [11/100], Step [400/420], Loss [0.2566206753253937]\n",
      "Epoch [12/100], Step [100/420], Loss [0.1856430470943451]\n",
      "Epoch [12/100], Step [200/420], Loss [0.2682710886001587]\n",
      "Epoch [12/100], Step [300/420], Loss [0.19398634135723114]\n",
      "Epoch [12/100], Step [400/420], Loss [0.34260180592536926]\n",
      "Epoch [13/100], Step [100/420], Loss [0.12222805619239807]\n",
      "Epoch [13/100], Step [200/420], Loss [0.3223457634449005]\n",
      "Epoch [13/100], Step [300/420], Loss [0.3394903540611267]\n",
      "Epoch [13/100], Step [400/420], Loss [0.3198062479496002]\n",
      "Epoch [14/100], Step [100/420], Loss [0.2695479094982147]\n",
      "Epoch [14/100], Step [200/420], Loss [0.33287808299064636]\n",
      "Epoch [14/100], Step [300/420], Loss [0.35097408294677734]\n",
      "Epoch [14/100], Step [400/420], Loss [0.307878315448761]\n",
      "Epoch [15/100], Step [100/420], Loss [0.3229959011077881]\n",
      "Epoch [15/100], Step [200/420], Loss [0.17919163405895233]\n",
      "Epoch [15/100], Step [300/420], Loss [0.2549911141395569]\n",
      "Epoch [15/100], Step [400/420], Loss [0.2135089635848999]\n",
      "Epoch [16/100], Step [100/420], Loss [0.1996293067932129]\n",
      "Epoch [16/100], Step [200/420], Loss [0.34843379259109497]\n",
      "Epoch [16/100], Step [300/420], Loss [0.1769751012325287]\n",
      "Epoch [16/100], Step [400/420], Loss [0.3640056550502777]\n",
      "Epoch [17/100], Step [100/420], Loss [0.23664480447769165]\n",
      "Epoch [17/100], Step [200/420], Loss [0.30465230345726013]\n",
      "Epoch [17/100], Step [300/420], Loss [0.22289042174816132]\n",
      "Epoch [17/100], Step [400/420], Loss [0.25257161259651184]\n",
      "Epoch [18/100], Step [100/420], Loss [0.34329715371131897]\n",
      "Epoch [18/100], Step [200/420], Loss [0.2708777189254761]\n",
      "Epoch [18/100], Step [300/420], Loss [0.215858593583107]\n",
      "Epoch [18/100], Step [400/420], Loss [0.22544682025909424]\n",
      "Epoch [19/100], Step [100/420], Loss [0.2555833160877228]\n",
      "Epoch [19/100], Step [200/420], Loss [0.23352833092212677]\n",
      "Epoch [19/100], Step [300/420], Loss [0.24398797750473022]\n",
      "Epoch [19/100], Step [400/420], Loss [0.17435365915298462]\n",
      "Epoch [20/100], Step [100/420], Loss [0.3903702199459076]\n",
      "Epoch [20/100], Step [200/420], Loss [0.21499429643154144]\n",
      "Epoch [20/100], Step [300/420], Loss [0.3680569529533386]\n",
      "Epoch [20/100], Step [400/420], Loss [0.262986421585083]\n",
      "Epoch [21/100], Step [100/420], Loss [0.2869234085083008]\n",
      "Epoch [21/100], Step [200/420], Loss [0.37964314222335815]\n",
      "Epoch [21/100], Step [300/420], Loss [0.29007771611213684]\n",
      "Epoch [21/100], Step [400/420], Loss [0.3014794886112213]\n",
      "Epoch [22/100], Step [100/420], Loss [0.19296586513519287]\n",
      "Epoch [22/100], Step [200/420], Loss [0.1365656554698944]\n",
      "Epoch [22/100], Step [300/420], Loss [0.20269162952899933]\n",
      "Epoch [22/100], Step [400/420], Loss [0.2729890048503876]\n",
      "Epoch [23/100], Step [100/420], Loss [0.24922756850719452]\n",
      "Epoch [23/100], Step [200/420], Loss [0.31830140948295593]\n",
      "Epoch [23/100], Step [300/420], Loss [0.32423460483551025]\n",
      "Epoch [23/100], Step [400/420], Loss [0.2615646719932556]\n",
      "Epoch [24/100], Step [100/420], Loss [0.2223546952009201]\n",
      "Epoch [24/100], Step [200/420], Loss [0.27154242992401123]\n",
      "Epoch [24/100], Step [300/420], Loss [0.25385329127311707]\n",
      "Epoch [24/100], Step [400/420], Loss [0.18173947930335999]\n",
      "Epoch [25/100], Step [100/420], Loss [0.16184940934181213]\n",
      "Epoch [25/100], Step [200/420], Loss [0.3059975802898407]\n",
      "Epoch [25/100], Step [300/420], Loss [0.23459120094776154]\n",
      "Epoch [25/100], Step [400/420], Loss [0.24282953143119812]\n",
      "Epoch [26/100], Step [100/420], Loss [0.3038114011287689]\n",
      "Epoch [26/100], Step [200/420], Loss [0.22439879179000854]\n",
      "Epoch [26/100], Step [300/420], Loss [0.1737913340330124]\n",
      "Epoch [26/100], Step [400/420], Loss [0.21264567971229553]\n",
      "Epoch [27/100], Step [100/420], Loss [0.19111941754817963]\n",
      "Epoch [27/100], Step [200/420], Loss [0.15766842663288116]\n",
      "Epoch [27/100], Step [300/420], Loss [0.36021727323532104]\n",
      "Epoch [27/100], Step [400/420], Loss [0.2826279103755951]\n",
      "Epoch [28/100], Step [100/420], Loss [0.19486279785633087]\n",
      "Epoch [28/100], Step [200/420], Loss [0.3124851584434509]\n",
      "Epoch [28/100], Step [300/420], Loss [0.22159352898597717]\n",
      "Epoch [28/100], Step [400/420], Loss [0.2705066204071045]\n",
      "Epoch [29/100], Step [100/420], Loss [0.2554611265659332]\n",
      "Epoch [29/100], Step [200/420], Loss [0.3049357533454895]\n",
      "Epoch [29/100], Step [300/420], Loss [0.38103318214416504]\n",
      "Epoch [29/100], Step [400/420], Loss [0.24939872324466705]\n",
      "Epoch [30/100], Step [100/420], Loss [0.4415585398674011]\n",
      "Epoch [30/100], Step [200/420], Loss [0.14174872636795044]\n",
      "Epoch [30/100], Step [300/420], Loss [0.21612314879894257]\n",
      "Epoch [30/100], Step [400/420], Loss [0.19492672383785248]\n",
      "Epoch [31/100], Step [100/420], Loss [0.19860826432704926]\n",
      "Epoch [31/100], Step [200/420], Loss [0.35625389218330383]\n",
      "Epoch [31/100], Step [300/420], Loss [0.24480512738227844]\n",
      "Epoch [31/100], Step [400/420], Loss [0.23991332948207855]\n",
      "Epoch [32/100], Step [100/420], Loss [0.14057493209838867]\n",
      "Epoch [32/100], Step [200/420], Loss [0.19566181302070618]\n",
      "Epoch [32/100], Step [300/420], Loss [0.19946470856666565]\n",
      "Epoch [32/100], Step [400/420], Loss [0.22884435951709747]\n",
      "Epoch [33/100], Step [100/420], Loss [0.19441722333431244]\n",
      "Epoch [33/100], Step [200/420], Loss [0.32403847575187683]\n",
      "Epoch [33/100], Step [300/420], Loss [0.18235239386558533]\n",
      "Epoch [33/100], Step [400/420], Loss [0.20779985189437866]\n",
      "Epoch [34/100], Step [100/420], Loss [0.3593943417072296]\n",
      "Epoch [34/100], Step [200/420], Loss [0.22181659936904907]\n",
      "Epoch [34/100], Step [300/420], Loss [0.1704118549823761]\n",
      "Epoch [34/100], Step [400/420], Loss [0.24978949129581451]\n",
      "Epoch [35/100], Step [100/420], Loss [0.2544635832309723]\n",
      "Epoch [35/100], Step [200/420], Loss [0.1946464478969574]\n",
      "Epoch [35/100], Step [300/420], Loss [0.22767814993858337]\n",
      "Epoch [35/100], Step [400/420], Loss [0.14203941822052002]\n",
      "Epoch [36/100], Step [100/420], Loss [0.36253735423088074]\n",
      "Epoch [36/100], Step [200/420], Loss [0.20615613460540771]\n",
      "Epoch [36/100], Step [300/420], Loss [0.4265335202217102]\n",
      "Epoch [36/100], Step [400/420], Loss [0.1976572573184967]\n",
      "Epoch [37/100], Step [100/420], Loss [0.1958063691854477]\n",
      "Epoch [37/100], Step [200/420], Loss [0.15834897756576538]\n",
      "Epoch [37/100], Step [300/420], Loss [0.41875529289245605]\n",
      "Epoch [37/100], Step [400/420], Loss [0.19098763167858124]\n",
      "Epoch [38/100], Step [100/420], Loss [0.26894572377204895]\n",
      "Epoch [38/100], Step [200/420], Loss [0.3925148844718933]\n",
      "Epoch [38/100], Step [300/420], Loss [0.3541930317878723]\n",
      "Epoch [38/100], Step [400/420], Loss [0.286255806684494]\n",
      "Epoch [39/100], Step [100/420], Loss [0.22123770415782928]\n",
      "Epoch [39/100], Step [200/420], Loss [0.33522820472717285]\n",
      "Epoch [39/100], Step [300/420], Loss [0.22786594927310944]\n",
      "Epoch [39/100], Step [400/420], Loss [0.13173207640647888]\n",
      "Epoch [40/100], Step [100/420], Loss [0.22123414278030396]\n",
      "Epoch [40/100], Step [200/420], Loss [0.21947617828845978]\n",
      "Epoch [40/100], Step [300/420], Loss [0.2929879128932953]\n",
      "Epoch [40/100], Step [400/420], Loss [0.2461177110671997]\n",
      "Epoch [41/100], Step [100/420], Loss [0.2766268253326416]\n",
      "Epoch [41/100], Step [200/420], Loss [0.1975894570350647]\n",
      "Epoch [41/100], Step [300/420], Loss [0.11367226392030716]\n",
      "Epoch [41/100], Step [400/420], Loss [0.17918792366981506]\n",
      "Epoch [42/100], Step [100/420], Loss [0.2238692343235016]\n",
      "Epoch [42/100], Step [200/420], Loss [0.2050803154706955]\n",
      "Epoch [42/100], Step [300/420], Loss [0.2795397639274597]\n",
      "Epoch [42/100], Step [400/420], Loss [0.23393431305885315]\n",
      "Epoch [43/100], Step [100/420], Loss [0.2704766094684601]\n",
      "Epoch [43/100], Step [200/420], Loss [0.20271354913711548]\n",
      "Epoch [43/100], Step [300/420], Loss [0.31602540612220764]\n",
      "Epoch [43/100], Step [400/420], Loss [0.20067931711673737]\n",
      "Epoch [44/100], Step [100/420], Loss [0.21088361740112305]\n",
      "Epoch [44/100], Step [200/420], Loss [0.31432485580444336]\n",
      "Epoch [44/100], Step [300/420], Loss [0.42440199851989746]\n",
      "Epoch [44/100], Step [400/420], Loss [0.2744733691215515]\n",
      "Epoch [45/100], Step [100/420], Loss [0.18045879900455475]\n",
      "Epoch [45/100], Step [200/420], Loss [0.26867160201072693]\n",
      "Epoch [45/100], Step [300/420], Loss [0.1773516684770584]\n",
      "Epoch [45/100], Step [400/420], Loss [0.1796567738056183]\n",
      "Epoch [46/100], Step [100/420], Loss [0.23661985993385315]\n",
      "Epoch [46/100], Step [200/420], Loss [0.29223498702049255]\n",
      "Epoch [46/100], Step [300/420], Loss [0.3422008156776428]\n",
      "Epoch [46/100], Step [400/420], Loss [0.3594691753387451]\n",
      "Epoch [47/100], Step [100/420], Loss [0.11710429936647415]\n",
      "Epoch [47/100], Step [200/420], Loss [0.21470409631729126]\n",
      "Epoch [47/100], Step [300/420], Loss [0.19313594698905945]\n",
      "Epoch [47/100], Step [400/420], Loss [0.21580824255943298]\n",
      "Epoch [48/100], Step [100/420], Loss [0.36491668224334717]\n",
      "Epoch [48/100], Step [200/420], Loss [0.3013611137866974]\n",
      "Epoch [48/100], Step [300/420], Loss [0.1288774460554123]\n",
      "Epoch [48/100], Step [400/420], Loss [0.21902534365653992]\n",
      "Epoch [49/100], Step [100/420], Loss [0.20318752527236938]\n",
      "Epoch [49/100], Step [200/420], Loss [0.2635507881641388]\n",
      "Epoch [49/100], Step [300/420], Loss [0.2555338740348816]\n",
      "Epoch [49/100], Step [400/420], Loss [0.15720246732234955]\n",
      "Epoch [50/100], Step [100/420], Loss [0.2532631456851959]\n",
      "Epoch [50/100], Step [200/420], Loss [0.2545087933540344]\n",
      "Epoch [50/100], Step [300/420], Loss [0.19705112278461456]\n",
      "Epoch [50/100], Step [400/420], Loss [0.2595222592353821]\n",
      "Epoch [51/100], Step [100/420], Loss [0.20260797441005707]\n",
      "Epoch [51/100], Step [200/420], Loss [0.22569309175014496]\n",
      "Epoch [51/100], Step [300/420], Loss [0.3748680353164673]\n",
      "Epoch [51/100], Step [400/420], Loss [0.2679542005062103]\n",
      "Epoch [52/100], Step [100/420], Loss [0.19860988855361938]\n",
      "Epoch [52/100], Step [200/420], Loss [0.19828328490257263]\n",
      "Epoch [52/100], Step [300/420], Loss [0.2258756458759308]\n",
      "Epoch [52/100], Step [400/420], Loss [0.11162018775939941]\n",
      "Epoch [53/100], Step [100/420], Loss [0.23950672149658203]\n",
      "Epoch [53/100], Step [200/420], Loss [0.2856307923793793]\n",
      "Epoch [53/100], Step [300/420], Loss [0.33570313453674316]\n",
      "Epoch [53/100], Step [400/420], Loss [0.15461485087871552]\n",
      "Epoch [54/100], Step [100/420], Loss [0.16965870559215546]\n",
      "Epoch [54/100], Step [200/420], Loss [0.17433162033557892]\n",
      "Epoch [54/100], Step [300/420], Loss [0.1640419214963913]\n",
      "Epoch [54/100], Step [400/420], Loss [0.19720910489559174]\n",
      "Epoch [55/100], Step [100/420], Loss [0.31627315282821655]\n",
      "Epoch [55/100], Step [200/420], Loss [0.19851134717464447]\n",
      "Epoch [55/100], Step [300/420], Loss [0.13512881100177765]\n",
      "Epoch [55/100], Step [400/420], Loss [0.15808650851249695]\n",
      "Epoch [56/100], Step [100/420], Loss [0.18856218457221985]\n",
      "Epoch [56/100], Step [200/420], Loss [0.1846030056476593]\n",
      "Epoch [56/100], Step [300/420], Loss [0.2722032070159912]\n",
      "Epoch [56/100], Step [400/420], Loss [0.20538608729839325]\n",
      "Epoch [57/100], Step [100/420], Loss [0.21544981002807617]\n",
      "Epoch [57/100], Step [200/420], Loss [0.12647081911563873]\n",
      "Epoch [57/100], Step [300/420], Loss [0.2550698518753052]\n",
      "Epoch [57/100], Step [400/420], Loss [0.31319376826286316]\n",
      "Epoch [58/100], Step [100/420], Loss [0.1689256727695465]\n",
      "Epoch [58/100], Step [200/420], Loss [0.23874659836292267]\n",
      "Epoch [58/100], Step [300/420], Loss [0.24573388695716858]\n",
      "Epoch [58/100], Step [400/420], Loss [0.2303483933210373]\n",
      "Epoch [59/100], Step [100/420], Loss [0.18109245598316193]\n",
      "Epoch [59/100], Step [200/420], Loss [0.14730271697044373]\n",
      "Epoch [59/100], Step [300/420], Loss [0.11674728989601135]\n",
      "Epoch [59/100], Step [400/420], Loss [0.15023913979530334]\n",
      "Epoch [60/100], Step [100/420], Loss [0.2987569272518158]\n",
      "Epoch [60/100], Step [200/420], Loss [0.09818597137928009]\n",
      "Epoch [60/100], Step [300/420], Loss [0.29676729440689087]\n",
      "Epoch [60/100], Step [400/420], Loss [0.14094114303588867]\n",
      "Epoch [61/100], Step [100/420], Loss [0.17231081426143646]\n",
      "Epoch [61/100], Step [200/420], Loss [0.18884098529815674]\n",
      "Epoch [61/100], Step [300/420], Loss [0.20064158737659454]\n",
      "Epoch [61/100], Step [400/420], Loss [0.10688196122646332]\n",
      "Epoch [62/100], Step [100/420], Loss [0.1958639770746231]\n",
      "Epoch [62/100], Step [200/420], Loss [0.2199268788099289]\n",
      "Epoch [62/100], Step [300/420], Loss [0.2878970205783844]\n",
      "Epoch [62/100], Step [400/420], Loss [0.17301541566848755]\n",
      "Epoch [63/100], Step [100/420], Loss [0.2171643078327179]\n",
      "Epoch [63/100], Step [200/420], Loss [0.19187898933887482]\n",
      "Epoch [63/100], Step [300/420], Loss [0.1943383365869522]\n",
      "Epoch [63/100], Step [400/420], Loss [0.24365021288394928]\n",
      "Epoch [64/100], Step [100/420], Loss [0.26264816522598267]\n",
      "Epoch [64/100], Step [200/420], Loss [0.13489025831222534]\n",
      "Epoch [64/100], Step [300/420], Loss [0.1999950259923935]\n",
      "Epoch [64/100], Step [400/420], Loss [0.09792058914899826]\n",
      "Epoch [65/100], Step [100/420], Loss [0.17354325950145721]\n",
      "Epoch [65/100], Step [200/420], Loss [0.16843542456626892]\n",
      "Epoch [65/100], Step [300/420], Loss [0.3571816682815552]\n",
      "Epoch [65/100], Step [400/420], Loss [0.2699294984340668]\n",
      "Epoch [66/100], Step [100/420], Loss [0.17035435140132904]\n",
      "Epoch [66/100], Step [200/420], Loss [0.26690948009490967]\n",
      "Epoch [66/100], Step [300/420], Loss [0.2739230692386627]\n",
      "Epoch [66/100], Step [400/420], Loss [0.2250526398420334]\n",
      "Epoch [67/100], Step [100/420], Loss [0.20395469665527344]\n",
      "Epoch [67/100], Step [200/420], Loss [0.2996844947338104]\n",
      "Epoch [67/100], Step [300/420], Loss [0.31519943475723267]\n",
      "Epoch [67/100], Step [400/420], Loss [0.3127548098564148]\n",
      "Epoch [68/100], Step [100/420], Loss [0.13336575031280518]\n",
      "Epoch [68/100], Step [200/420], Loss [0.19885896146297455]\n",
      "Epoch [68/100], Step [300/420], Loss [0.29263681173324585]\n",
      "Epoch [68/100], Step [400/420], Loss [0.20507745444774628]\n",
      "Epoch [69/100], Step [100/420], Loss [0.19419534504413605]\n",
      "Epoch [69/100], Step [200/420], Loss [0.22228118777275085]\n",
      "Epoch [69/100], Step [300/420], Loss [0.08243554085493088]\n",
      "Epoch [69/100], Step [400/420], Loss [0.1623004972934723]\n",
      "Epoch [70/100], Step [100/420], Loss [0.18992602825164795]\n",
      "Epoch [70/100], Step [200/420], Loss [0.3015444278717041]\n",
      "Epoch [70/100], Step [300/420], Loss [0.19787296652793884]\n",
      "Epoch [70/100], Step [400/420], Loss [0.0831851214170456]\n",
      "Epoch [71/100], Step [100/420], Loss [0.12927787005901337]\n",
      "Epoch [71/100], Step [200/420], Loss [0.19830000400543213]\n",
      "Epoch [71/100], Step [300/420], Loss [0.3195491433143616]\n",
      "Epoch [71/100], Step [400/420], Loss [0.2416161149740219]\n",
      "Epoch [72/100], Step [100/420], Loss [0.16900652647018433]\n",
      "Epoch [72/100], Step [200/420], Loss [0.08353777229785919]\n",
      "Epoch [72/100], Step [300/420], Loss [0.18160486221313477]\n",
      "Epoch [72/100], Step [400/420], Loss [0.17118854820728302]\n",
      "Epoch [73/100], Step [100/420], Loss [0.3887794613838196]\n",
      "Epoch [73/100], Step [200/420], Loss [0.2283354252576828]\n",
      "Epoch [73/100], Step [300/420], Loss [0.23107898235321045]\n",
      "Epoch [73/100], Step [400/420], Loss [0.1605384647846222]\n",
      "Epoch [74/100], Step [100/420], Loss [0.09836291521787643]\n",
      "Epoch [74/100], Step [200/420], Loss [0.15706714987754822]\n",
      "Epoch [74/100], Step [300/420], Loss [0.18518781661987305]\n",
      "Epoch [74/100], Step [400/420], Loss [0.2446162849664688]\n",
      "Epoch [75/100], Step [100/420], Loss [0.1703639179468155]\n",
      "Epoch [75/100], Step [200/420], Loss [0.0918433889746666]\n",
      "Epoch [75/100], Step [300/420], Loss [0.26486751437187195]\n",
      "Epoch [75/100], Step [400/420], Loss [0.15568594634532928]\n",
      "Epoch [76/100], Step [100/420], Loss [0.09728524833917618]\n",
      "Epoch [76/100], Step [200/420], Loss [0.23756328225135803]\n",
      "Epoch [76/100], Step [300/420], Loss [0.28898945450782776]\n",
      "Epoch [76/100], Step [400/420], Loss [0.08326117694377899]\n",
      "Epoch [77/100], Step [100/420], Loss [0.19199241697788239]\n",
      "Epoch [77/100], Step [200/420], Loss [0.16854557394981384]\n",
      "Epoch [77/100], Step [300/420], Loss [0.5065797567367554]\n",
      "Epoch [77/100], Step [400/420], Loss [0.14707176387310028]\n",
      "Epoch [78/100], Step [100/420], Loss [0.10709955543279648]\n",
      "Epoch [78/100], Step [200/420], Loss [0.14320825040340424]\n",
      "Epoch [78/100], Step [300/420], Loss [0.18167482316493988]\n",
      "Epoch [78/100], Step [400/420], Loss [0.31050339341163635]\n",
      "Epoch [79/100], Step [100/420], Loss [0.17030265927314758]\n",
      "Epoch [79/100], Step [200/420], Loss [0.11473748832941055]\n",
      "Epoch [79/100], Step [300/420], Loss [0.11183059960603714]\n",
      "Epoch [79/100], Step [400/420], Loss [0.18597322702407837]\n",
      "Epoch [80/100], Step [100/420], Loss [0.17524264752864838]\n",
      "Epoch [80/100], Step [200/420], Loss [0.12612468004226685]\n",
      "Epoch [80/100], Step [300/420], Loss [0.2248287796974182]\n",
      "Epoch [80/100], Step [400/420], Loss [0.22699756920337677]\n",
      "Epoch [81/100], Step [100/420], Loss [0.15019641816616058]\n",
      "Epoch [81/100], Step [200/420], Loss [0.18576252460479736]\n",
      "Epoch [81/100], Step [300/420], Loss [0.2376754879951477]\n",
      "Epoch [81/100], Step [400/420], Loss [0.20224177837371826]\n",
      "Epoch [82/100], Step [100/420], Loss [0.08192814886569977]\n",
      "Epoch [82/100], Step [200/420], Loss [0.1690962165594101]\n",
      "Epoch [82/100], Step [300/420], Loss [0.25069668889045715]\n",
      "Epoch [82/100], Step [400/420], Loss [0.15089325606822968]\n",
      "Epoch [83/100], Step [100/420], Loss [0.15496250987052917]\n",
      "Epoch [83/100], Step [200/420], Loss [0.14682503044605255]\n",
      "Epoch [83/100], Step [300/420], Loss [0.19339610636234283]\n",
      "Epoch [83/100], Step [400/420], Loss [0.15265348553657532]\n",
      "Epoch [84/100], Step [100/420], Loss [0.1887233704328537]\n",
      "Epoch [84/100], Step [200/420], Loss [0.27896401286125183]\n",
      "Epoch [84/100], Step [300/420], Loss [0.10511254519224167]\n",
      "Epoch [84/100], Step [400/420], Loss [0.18412697315216064]\n",
      "Epoch [85/100], Step [100/420], Loss [0.15746711194515228]\n",
      "Epoch [85/100], Step [200/420], Loss [0.1957416534423828]\n",
      "Epoch [85/100], Step [300/420], Loss [0.2127043604850769]\n",
      "Epoch [85/100], Step [400/420], Loss [0.16750064492225647]\n",
      "Epoch [86/100], Step [100/420], Loss [0.049084171652793884]\n",
      "Epoch [86/100], Step [200/420], Loss [0.13559764623641968]\n",
      "Epoch [86/100], Step [300/420], Loss [0.15616518259048462]\n",
      "Epoch [86/100], Step [400/420], Loss [0.2113332599401474]\n",
      "Epoch [87/100], Step [100/420], Loss [0.20032364130020142]\n",
      "Epoch [87/100], Step [200/420], Loss [0.32136279344558716]\n",
      "Epoch [87/100], Step [300/420], Loss [0.14879173040390015]\n",
      "Epoch [87/100], Step [400/420], Loss [0.18544000387191772]\n",
      "Epoch [88/100], Step [100/420], Loss [0.11096028983592987]\n",
      "Epoch [88/100], Step [200/420], Loss [0.10601231455802917]\n",
      "Epoch [88/100], Step [300/420], Loss [0.2469993233680725]\n",
      "Epoch [88/100], Step [400/420], Loss [0.366346538066864]\n",
      "Epoch [89/100], Step [100/420], Loss [0.17371608316898346]\n",
      "Epoch [89/100], Step [200/420], Loss [0.27461621165275574]\n",
      "Epoch [89/100], Step [300/420], Loss [0.09475085884332657]\n",
      "Epoch [89/100], Step [400/420], Loss [0.19446711242198944]\n",
      "Epoch [90/100], Step [100/420], Loss [0.1644337773323059]\n",
      "Epoch [90/100], Step [200/420], Loss [0.19133394956588745]\n",
      "Epoch [90/100], Step [300/420], Loss [0.07332686334848404]\n",
      "Epoch [90/100], Step [400/420], Loss [0.23813527822494507]\n",
      "Epoch [91/100], Step [100/420], Loss [0.18268898129463196]\n",
      "Epoch [91/100], Step [200/420], Loss [0.17196878790855408]\n",
      "Epoch [91/100], Step [300/420], Loss [0.23125581443309784]\n",
      "Epoch [91/100], Step [400/420], Loss [0.3265073001384735]\n",
      "Epoch [92/100], Step [100/420], Loss [0.14426064491271973]\n",
      "Epoch [92/100], Step [200/420], Loss [0.19322702288627625]\n",
      "Epoch [92/100], Step [300/420], Loss [0.20836856961250305]\n",
      "Epoch [92/100], Step [400/420], Loss [0.06990733742713928]\n",
      "Epoch [93/100], Step [100/420], Loss [0.1911677122116089]\n",
      "Epoch [93/100], Step [200/420], Loss [0.35781368613243103]\n",
      "Epoch [93/100], Step [300/420], Loss [0.2633059024810791]\n",
      "Epoch [93/100], Step [400/420], Loss [0.11796902865171432]\n",
      "Epoch [94/100], Step [100/420], Loss [0.18271566927433014]\n",
      "Epoch [94/100], Step [200/420], Loss [0.22556722164154053]\n",
      "Epoch [94/100], Step [300/420], Loss [0.10540241003036499]\n",
      "Epoch [94/100], Step [400/420], Loss [0.16161461174488068]\n",
      "Epoch [95/100], Step [100/420], Loss [0.2436629682779312]\n",
      "Epoch [95/100], Step [200/420], Loss [0.09332091361284256]\n",
      "Epoch [95/100], Step [300/420], Loss [0.1262785792350769]\n",
      "Epoch [95/100], Step [400/420], Loss [0.22481153905391693]\n",
      "Epoch [96/100], Step [100/420], Loss [0.21461424231529236]\n",
      "Epoch [96/100], Step [200/420], Loss [0.33453667163848877]\n",
      "Epoch [96/100], Step [300/420], Loss [0.2974972128868103]\n",
      "Epoch [96/100], Step [400/420], Loss [0.22436822950839996]\n",
      "Epoch [97/100], Step [100/420], Loss [0.18810388445854187]\n",
      "Epoch [97/100], Step [200/420], Loss [0.131692573428154]\n",
      "Epoch [97/100], Step [300/420], Loss [0.21107979118824005]\n",
      "Epoch [97/100], Step [400/420], Loss [0.21150213479995728]\n",
      "Epoch [98/100], Step [100/420], Loss [0.25193074345588684]\n",
      "Epoch [98/100], Step [200/420], Loss [0.09979533404111862]\n",
      "Epoch [98/100], Step [300/420], Loss [0.1521868109703064]\n",
      "Epoch [98/100], Step [400/420], Loss [0.3725593686103821]\n",
      "Epoch [99/100], Step [100/420], Loss [0.22791685163974762]\n",
      "Epoch [99/100], Step [200/420], Loss [0.2523229718208313]\n",
      "Epoch [99/100], Step [300/420], Loss [0.19587522745132446]\n",
      "Epoch [99/100], Step [400/420], Loss [0.21943053603172302]\n",
      "Epoch [100/100], Step [100/420], Loss [0.15000388026237488]\n",
      "Epoch [100/100], Step [200/420], Loss [0.15097969770431519]\n",
      "Epoch [100/100], Step [300/420], Loss [0.6422575116157532]\n",
      "Epoch [100/100], Step [400/420], Loss [0.16503113508224487]\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #Forward pass and loss\n",
    "        ouputs = model(images)\n",
    "        loss = criterion(ouputs,labels)\n",
    "\n",
    "        #Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if(i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{n_total_steps}], Loss [{loss}]')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Inference without gradients\n",
    "with torch.no_grad():\n",
    "    X_test_ten = X_test_ten.to(device)\n",
    "    outputs = model(X_test_ten)\n",
    "    _, predicted_labels = torch.max(outputs, dim=1)\n",
    "    predicted_labels = predicted_labels.cpu().numpy()\n",
    "\n",
    "# Create DataFrame with ID and Label columns\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': range(len(predicted_labels)),\n",
    "    'Label': predicted_labels\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
